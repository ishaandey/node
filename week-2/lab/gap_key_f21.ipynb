{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Notes on the Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data Documentation:\n",
    "<br>**Description**: Synthetic dataset from Gap Inc., representing a random sample of individual purchases from Q1 FY2020. Each row is a unique item purchased in an order\n",
    "<br><br>\n",
    "\n",
    "| **Feature** | **Description**    | **Sample Value(s)**  |\n",
    "| ------- | -----------    | ------------- |\n",
    "| OrderID | Unique identifier per transaction (7-digit) | DRW7C20   |\n",
    "| CustomerID | Unique identifier per customer (5-digit) | KP441   |\n",
    "| ProductID  | Unique identifier per item (8-digit) | 13-817-239 |\n",
    "| StoreID | Unique identifier per store (4-digit) | #4176 |\n",
    "| OrderType | How purchase was completed  | InStore, HomeDelivery, Online |\n",
    "| Timestamp | Timestamp of transaction (YYYY-MM-DD) | 2020-01-18 10:13:56\t |\n",
    "| Brand | Which reporting segment of Gap Inc. bought from | Banana Republic |\n",
    "| ItemSize | Size of item | XS, S, M, L, X, XL |\n",
    "| ProductName | Name of item associated with item identifier | Pink Polo by Kanye |\n",
    "| Collection | Which part of store | Denim Shop |\n",
    "| Price | Listed price of item | $29.95 |\n",
    "| ClearanceType | Type of clearance | Retail, Clearance, Final Sale |\n",
    "| DiscountType | If Gap Card rewards was used | Reward points, Promotion, GapCash, Other |\n",
    "| StoreName | Store name (i.e. Mall), or facility where online order was shipped from | Fair Oaks Mall |\n",
    "| Location | State of store location | VA |\n",
    "\n",
    "<br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Some comments about the data**: \n",
    "\n",
    "<br>In the real world, data comes from databases. Each transaction gets recorded as a observation, what item was purchased, at which store, by which customer. We can refer to these items by name, but there can be confusion if there's overlap. (i.e. Two customers with the same name, or two products with the same name)\n",
    "\n",
    "<br>Instead, we can assign **unique identifiers** to each item, store, customer. Even if they have the same name, they'll be distinct in the eyes of the data. Since these are randomly assigned, they can look pretty ugly, but just know that **each ID is associated just one thing**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Why we're using GroupBys**:\n",
    "\n",
    "<br> Sometimes information in observations can be duplicated. Each row is a item that was purchased by some customer, on some day, at some store. That customer could have purchased *multiple items* in that transaction. To show that, we give each observation from the same transaction the *same OrderID*.\n",
    "\n",
    "<br> This means that if we wanted some information at the transaction level, i.e. how many items were purchased per transaction, we could **first groupby each OrderID**, and then get some summary statistic, i.e 'count' to capture how many items are in each order.\n",
    "\n",
    "<br> Now we have data where each row is a different order. To get the average number of items purchased per transaction, we now **average the grouped data**, and come up with a single number that summarizes that series. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Package & Data Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Import our usual packages, pandas and numpy. Use pandas to read in the CSV\n",
    "\n",
    "2. Note that we'll have to pass in a new parameter, `sep=|`, to reflect that the raw data is stored a bit differently than usual\n",
    "\n",
    "3. Check out the dimensions of the dataset, then take a look at the dataframe itself.\n",
    "\n",
    "URL = `https://raw.githubusercontent.com/ishaandey/node/master/week-2/lab/gap.csv`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ishaandey/node/master/week-2/lab/gap.csv', sep='|') # We're using a pipe instead of comma to seperate here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(df.shape)\n",
    "df.sample(2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4031, 14)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>OrderType</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Brand</th>\n",
       "      <th>ItemSize</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Collection</th>\n",
       "      <th>Price</th>\n",
       "      <th>ClearanceType</th>\n",
       "      <th>StoreName</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>523FFKW</td>\n",
       "      <td>IQ441</td>\n",
       "      <td>09-875-876</td>\n",
       "      <td>#5101</td>\n",
       "      <td>InStore</td>\n",
       "      <td>2020-03-19 23:52:23</td>\n",
       "      <td>Gap</td>\n",
       "      <td>S</td>\n",
       "      <td>Comfortable Jeans, Exclusive to Size(s): XXXS</td>\n",
       "      <td>Denim Shop</td>\n",
       "      <td>54.95</td>\n",
       "      <td>FullRetail</td>\n",
       "      <td>Leesburg Premium Outlets</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>C4ZF155</td>\n",
       "      <td>UY851</td>\n",
       "      <td>05-574-428</td>\n",
       "      <td>#1812</td>\n",
       "      <td>InStore</td>\n",
       "      <td>2020-01-06 16:39:47</td>\n",
       "      <td>Gap</td>\n",
       "      <td>XL</td>\n",
       "      <td>Hello, World! JavaScript Graphic Tee</td>\n",
       "      <td>Kids Tops</td>\n",
       "      <td>8.95</td>\n",
       "      <td>FullRetail</td>\n",
       "      <td>Williamsburg Premium Outlets</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OrderID CustomerID   ProductID StoreID OrderType            Timestamp  \\\n",
       "2731  523FFKW      IQ441  09-875-876   #5101   InStore  2020-03-19 23:52:23   \n",
       "2016  C4ZF155      UY851  05-574-428   #1812   InStore  2020-01-06 16:39:47   \n",
       "\n",
       "     Brand ItemSize                                    ProductName  \\\n",
       "2731   Gap        S  Comfortable Jeans, Exclusive to Size(s): XXXS   \n",
       "2016   Gap       XL           Hello, World! JavaScript Graphic Tee   \n",
       "\n",
       "      Collection  Price ClearanceType                     StoreName Location  \n",
       "2731  Denim Shop  54.95    FullRetail      Leesburg Premium Outlets       VA  \n",
       "2016   Kids Tops   8.95    FullRetail  Williamsburg Premium Outlets       VA  "
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collection Trends"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Questions (Easy):\n",
    "Let's take a look at total sales in various collections:\n",
    "1. First, subset down to the *Kids Tops* collection. Grab the price column, then take the sum of that. How much did Kids Tops sales total to?\n",
    "2. What about total sales for the Denim Shop collection? For Accessories? \n",
    "\n",
    "\n",
    "<br>Since it's getting pretty tedious to look for total sales in each collection, let's automate this by taking the sum of sales in each collection. To do so:\n",
    "3. Group the dataframe by Collection, grab the price column, then aggregate the rows by taking a sum across each collection.\n",
    "4. Do your answers here line up with what we found by the subset method?\n",
    "\n",
    "#### **Tips:**\n",
    "Here are a few hints to get you started:\n",
    "- Remember, there are different ways to subset using conditionals. For the *Kids Tops*, we want all the rows where the *Collection* column has the value *Kids Tops*.\n",
    "- We only want the price column for these questions, so how would we call a specific column? Then, how do we aggregate that column for total sales \n",
    "    - Are we going to use `.sum()`, `.min()`, `.max()`, or another function?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df[df.Collection == 'Kids Tops'].Price.sum() #1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13095.460000000001"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df[df.Collection == 'Denim Shop'].Price.sum() #2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19796.47"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df[df.Collection == 'Accessories'].Price.sum() #2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6139.860000000001"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df.groupby('Collection').Price.agg('sum') # 3"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Collection\n",
       "Accessories         6139.86\n",
       "Denim Shop         19796.47\n",
       "Kids Bottoms        4746.85\n",
       "Kids Tops          13095.46\n",
       "Men's Bottoms      28907.40\n",
       "Men's Tops         38469.18\n",
       "Women's Bottoms    36413.43\n",
       "Women's Tops       30972.46\n",
       "Name: Price, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(sum_by_collection['Kids Tops']) # 4\n",
    "print(kids_tops_sales)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Product Trends"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Questions (Easy):\n",
    "Let's take a look at some product trends:\n",
    "1. How many unique products are there? \n",
    "2. What different collections are there?\n",
    "3. What are top 10 best selling items (in terms of sale frequency)?\n",
    "4. How many times was the `N-A-P Logo Branded Sweater` purchased?\n",
    "<br>\n",
    "\n",
    "#### Tips:\n",
    "Functions you'll probably wanna use: `.unique()`, `.nunique()`, `.value_counts()` "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df.ProductName.nunique() # 1 "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df.Collection.unique() # 2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Accessories', 'Kids Tops', \"Men's Bottoms\", 'Denim Shop',\n",
       "       \"Men's Tops\", \"Women's Bottoms\", \"Women's Tops\", 'Kids Bottoms'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df.ProductName.value_counts().head() #3"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Tan Slacks for Serious Press Conference                  173\n",
       "Acid-Washed Low-Rise Jeans with LSD-tab-sized pockets    172\n",
       "Tan Suit Jacket for Casual Press Conference              150\n",
       "Let's-Wear-White-After-Labor-Day 3/4 Sleeve Blazer       133\n",
       "Sun.png Summer Collection Sundress                       126\n",
       "Name: ProductName, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "df.ProductName.value_counts()['N-A-P Logo Branded Sweater']\n",
    "# or\n",
    "len(df[df.ProductName == 'N-A-P Logo Branded Sweater']) #4"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segment Trends"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Questions (Easy - Medium):\n",
    "Let's take a look at some breakdowns by business segment, or brand.\n",
    "1. What were *total sales* by brand (in terms of $)?\n",
    "\n",
    "\n",
    "<br>Since a customer can buy multiple items in one transaction, or \"order\", use *OrderID* to prevent double counting.\n",
    "2. What  were the total number of *unique* orders per brand? \n",
    "3. How many orders of each type (`OrderType`) were completed?\n",
    "\n",
    "\n",
    "#### Tips:\n",
    "- First GroupBy, then Aggregate! `.groupby(by=)`, `.agg(func=)`\n",
    "    - Google possible aggregation arguments, like sum, average, or number of unique items"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "df.groupby('Brand').Price.agg('sum') #1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Brand\n",
       "Banana Republic    120011.82\n",
       "Gap                 58529.29\n",
       "Name: Price, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "df.groupby('Brand').OrderID.agg('nunique') #2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Brand\n",
       "Banana Republic    1349\n",
       "Gap                 823\n",
       "Name: OrderID, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "df.groupby('OrderType').OrderID.agg('nunique') #3"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderType\n",
       "HomeDelivery     576\n",
       "InStore         1361\n",
       "StorePickup      235\n",
       "Name: OrderID, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Store Trends"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Questions (Medium):\n",
    "Almost done! Think at the store level:\n",
    "1. Which stores have the lowest sales (in $)? Save its StoreID to a varable, `bad_store`\n",
    "2. How many orders does that store have? (Hint: Use `.index` to capture the key of a pd.Series object)\n",
    "3. What is the maximum number of HomeDelivery orders that any one store got?\n",
    "<br>\n",
    "\n",
    "#### Tips:\n",
    "- We're just chaining things together. Subset, then groupby, then pull a column, then aggregate, then apply a function, etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 1\n",
    "\n",
    "bad_store = df.groupby('StoreID').Price.agg('sum').sort_values(ascending=False).tail(1)\n",
    "bad_store"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StoreID\n",
       "#1047    10187.61\n",
       "#1812     4325.72\n",
       "#4291    11853.95\n",
       "#4479     8113.38\n",
       "#5101     4778.55\n",
       "#5627     7265.63\n",
       "#6042    10173.30\n",
       "#6569     7548.90\n",
       "#6658     9059.22\n",
       "#6802     4643.70\n",
       "#7038     9322.17\n",
       "#7104     4979.57\n",
       "#8271    10077.32\n",
       "#8289     4827.48\n",
       "#8425     5999.78\n",
       "#8803     6966.85\n",
       "#9033     9408.27\n",
       "#9112    10041.21\n",
       "#9367     5720.60\n",
       "#9543     7953.68\n",
       "#9612     9007.18\n",
       "#9837     4946.75\n",
       "#9901     4334.66\n",
       "#9981     7005.63\n",
       "Name: Price, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# 2\n",
    "df.groupby('StoreID').OrderID.agg('nunique')[bad_store.index]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StoreID\n",
       "#1812    68\n",
       "Name: OrderID, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "# 3\n",
    "df[df.OrderType == 'HomeDelivery'].groupby('StoreID').OrderID.agg('nunique').max()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "d0fa7c806679d6ffc40184b24ef308d82c68a18a4590df1b063471f044803a03"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}